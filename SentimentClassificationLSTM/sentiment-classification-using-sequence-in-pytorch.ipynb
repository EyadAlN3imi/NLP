{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification using RNN in PyTorch\n",
    "This notebook demonstrates how to build a simple Recurrent Neural Network (RNN) for sentiment Classification using PyTorch. We will preprocess text data using RegEx and nltk, train an RNN model, and evaluate its accuracy for sentiment classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:08.782638Z",
     "iopub.status.busy": "2025-04-07T15:30:08.782248Z",
     "iopub.status.idle": "2025-04-07T15:30:12.451055Z",
     "shell.execute_reply": "2025-04-07T15:30:12.450047Z",
     "shell.execute_reply.started": "2025-04-07T15:30:08.782609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets tqdm --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:12.453011Z",
     "iopub.status.busy": "2025-04-07T15:30:12.452662Z",
     "iopub.status.idle": "2025-04-07T15:30:12.458348Z",
     "shell.execute_reply": "2025-04-07T15:30:12.457335Z",
     "shell.execute_reply.started": "2025-04-07T15:30:12.452977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:12.460513Z",
     "iopub.status.busy": "2025-04-07T15:30:12.460222Z",
     "iopub.status.idle": "2025-04-07T15:30:12.550624Z",
     "shell.execute_reply": "2025-04-07T15:30:12.549758Z",
     "shell.execute_reply.started": "2025-04-07T15:30:12.460482Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure nltk requirements are downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:12.552218Z",
     "iopub.status.busy": "2025-04-07T15:30:12.551908Z",
     "iopub.status.idle": "2025-04-07T15:30:12.555844Z",
     "shell.execute_reply": "2025-04-07T15:30:12.555067Z",
     "shell.execute_reply.started": "2025-04-07T15:30:12.552195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:12.556769Z",
     "iopub.status.busy": "2025-04-07T15:30:12.556551Z",
     "iopub.status.idle": "2025-04-07T15:30:14.280083Z",
     "shell.execute_reply": "2025-04-07T15:30:14.279439Z",
     "shell.execute_reply.started": "2025-04-07T15:30:12.556750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load IMDb Dataset from Hugging Face\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Text Preprocessing Function\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    tokens = [word for word in tokens if word not in STOPWORDS]  # Remove stopwords\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "dataset['train'] = dataset['train'].map(lambda x: {\"text\": preprocess_text(x['text'])})\n",
    "dataset['test'] = dataset['test'].map(lambda x: {\"text\": preprocess_text(x['text'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:14.281098Z",
     "iopub.status.busy": "2025-04-07T15:30:14.280875Z",
     "iopub.status.idle": "2025-04-07T15:30:19.324192Z",
     "shell.execute_reply": "2025-04-07T15:30:19.323554Z",
     "shell.execute_reply.started": "2025-04-07T15:30:14.281078Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "word_to_index = {}\n",
    "index = 1  # Start indexing from 1 (0 for padding)\n",
    "\n",
    "for data in dataset['train']['text']:\n",
    "    for word in data:\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = index\n",
    "            index += 1\n",
    "\n",
    "# Convert text to numerical sequences\n",
    "def encode_text(text):#[x1,x2,x3] [10, 8, 100]\n",
    "    return [word_to_index.get(word, 0) for word in text]\n",
    "\n",
    "dataset['train'] = dataset['train'].map(lambda x: {'text': encode_text(x['text']), 'label': x['label']})\n",
    "dataset['test'] = dataset['test'].map(lambda x: {'text': encode_text(x['text']), 'label': x['label']})\n",
    "\n",
    "# Pad sequences to fixed length\n",
    "MAX_LEN = 100\n",
    "\n",
    "def pad_sequence(seq, max_len):\n",
    "    return seq[:max_len] + [0] * (max_len - len(seq))\n",
    "\n",
    "dataset['train'] = dataset['train'].map(lambda x: {'text': pad_sequence(x['text'], MAX_LEN), 'label': x['label']})\n",
    "dataset['test'] = dataset['test'].map(lambda x: {'text': pad_sequence(x['text'], MAX_LEN), 'label': x['label']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:19.325373Z",
     "iopub.status.busy": "2025-04-07T15:30:19.325064Z",
     "iopub.status.idle": "2025-04-07T15:30:22.391885Z",
     "shell.execute_reply": "2025-04-07T15:30:22.391155Z",
     "shell.execute_reply.started": "2025-04-07T15:30:19.325329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(dataset['train']['text'], dtype=torch.long)\n",
    "y_train = torch.tensor(dataset['train']['label'], dtype=torch.long)\n",
    "X_test = torch.tensor(dataset['test']['text'], dtype=torch.long)\n",
    "y_test = torch.tensor(dataset['test']['label'], dtype=torch.long)\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define the Sequence Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:22.394562Z",
     "iopub.status.busy": "2025-04-07T15:30:22.394348Z",
     "iopub.status.idle": "2025-04-07T15:30:22.399815Z",
     "shell.execute_reply": "2025-04-07T15:30:22.398862Z",
     "shell.execute_reply.started": "2025-04-07T15:30:22.394540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define RNN Model\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True, num_layers=1, bidirectional=False, device=device)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return self.fc(hidden.squeeze(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:22.401042Z",
     "iopub.status.busy": "2025-04-07T15:30:22.400780Z",
     "iopub.status.idle": "2025-04-07T15:30:22.413815Z",
     "shell.execute_reply": "2025-04-07T15:30:22.413095Z",
     "shell.execute_reply.started": "2025-04-07T15:30:22.401023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True, num_layers=1, bidirectional=False, device=device)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embedded)    \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:22.414675Z",
     "iopub.status.busy": "2025-04-07T15:30:22.414459Z",
     "iopub.status.idle": "2025-04-07T15:30:22.423732Z",
     "shell.execute_reply": "2025-04-07T15:30:22.423084Z",
     "shell.execute_reply.started": "2025-04-07T15:30:22.414656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LSTMBIClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True, num_layers=1, bidirectional=True, device=device)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  \n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:22.424694Z",
     "iopub.status.busy": "2025-04-07T15:30:22.424426Z",
     "iopub.status.idle": "2025-04-07T15:30:22.437013Z",
     "shell.execute_reply": "2025-04-07T15:30:22.436345Z",
     "shell.execute_reply.started": "2025-04-07T15:30:22.424672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LSTMMULClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True, \n",
    "                           num_layers=num_layers, bidirectional=True, device=device)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:22.438031Z",
     "iopub.status.busy": "2025-04-07T15:30:22.437728Z",
     "iopub.status.idle": "2025-04-07T15:30:22.599198Z",
     "shell.execute_reply": "2025-04-07T15:30:22.598552Z",
     "shell.execute_reply.started": "2025-04-07T15:30:22.438010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "VOCAB_SIZE = len(word_to_index) + 1\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 2\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMMULClassifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:30:22.600292Z",
     "iopub.status.busy": "2025-04-07T15:30:22.599979Z",
     "iopub.status.idle": "2025-04-07T15:34:16.345720Z",
     "shell.execute_reply": "2025-04-07T15:34:16.344952Z",
     "shell.execute_reply.started": "2025-04-07T15:30:22.600243Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6582\n",
      "Epoch 1, Loss: 0.4172\n",
      "Epoch 2, Loss: 0.2550\n",
      "Epoch 3, Loss: 0.1500\n",
      "Epoch 4, Loss: 0.0729\n",
      "Epoch 5, Loss: 0.0424\n",
      "Epoch 6, Loss: 0.0223\n",
      "Epoch 7, Loss: 0.0180\n",
      "Epoch 8, Loss: 0.0150\n",
      "Epoch 9, Loss: 0.0117\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    # progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
    "    for batch in train_loader:\n",
    "        texts, labels = batch\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(texts)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    if epoch%1 == 0:\n",
    "      print(f\"Epoch {epoch}, Loss: {epoch_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:34:16.346755Z",
     "iopub.status.busy": "2025-04-07T15:34:16.346470Z",
     "iopub.status.idle": "2025-04-07T15:34:23.784946Z",
     "shell.execute_reply": "2025-04-07T15:34:23.784002Z",
     "shell.execute_reply.started": "2025-04-07T15:34:16.346722Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            texts, labels = batch\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "\n",
    "            predictions = model(texts)\n",
    "            predicted = predictions.argmax(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T15:34:23.786219Z",
     "iopub.status.busy": "2025-04-07T15:34:23.785906Z",
     "iopub.status.idle": "2025-04-07T15:34:23.805069Z",
     "shell.execute_reply": "2025-04-07T15:34:23.804341Z",
     "shell.execute_reply.started": "2025-04-07T15:34:23.786183Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Great film! \n",
      "Sentiment: +\n",
      "Sentence: Bad film! \n",
      "Sentiment: -\n"
     ]
    }
   ],
   "source": [
    "# Function to predict sentiment on new sentences\n",
    "def predict_sentiment(model, sentence, max_len):\n",
    "    model.eval()\n",
    "    sequence = encode_text(preprocess_text(sentence))\n",
    "    padded_sequence = pad_sequence(sequence, max_len)\n",
    "    tensor = torch.LongTensor(padded_sequence).unsqueeze(0).to(device)\n",
    "    # prediction = torch.sigmoid(model(tensor).squeeze(1))\n",
    "    prediction = model(tensor)\n",
    "    return prediction.argmax(1).item()\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Great film!\"\n",
    "prediction = predict_sentiment(model, sentence, MAX_LEN)\n",
    "print(f'Sentence: {sentence} \\nSentiment: {\"+\" if prediction==1 else \"-\"}')  # 0 for negative, 1 for positive\n",
    "\n",
    "sentence = \"Bad film!\"\n",
    "prediction = predict_sentiment(model, sentence, MAX_LEN)\n",
    "print(f'Sentence: {sentence} \\nSentiment: {\"+\" if prediction==1 else \"-\"}')  # 0 for negative, 1 for positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "| **Model**       | **Training Loss Epoch 1** | **Training Loss Epoch 5** | **Training Loss Epoch 10** | **Test Accuracy (%)** |\n",
    "|-----------------|--------------------------|--------------------------|---------------------------|-----------------------|\n",
    "| RNN             | 0.70                    | 0.67                    | 0.48                     | 0.56                  |\n",
    "| LSTM            | 0.69                    | 0.17                    | 0.013                     | 0.80                 |\n",
    "| Bidirectional LSTM| 0.65                    | 0.11                    | 0.011                     | 0.80                  |\n",
    "| Multilayer LSTM | 0.65                    | 0.07                    | 0.010                     | 0.79                  |"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
